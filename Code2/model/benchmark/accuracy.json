{
  "model": "bigcode/tiny_starcoder_py (GGUF FP16)",
  "hardware": "1GB RAM, 2 CPU",
  "total_prompts": 50,
  "successful": 50,
  "failed": 0,
  "latency": {
    "overall_avg": 16.32,
    "easy_avg": 14.18,
    "medium_avg": 18.47,
    "min": 2.60,
    "max": 26.23,
    "std_dev": 7.24
  },
  "accuracy_assessment": {
    "note": "Code quality evaluation focuses on functional correctness and logic, not style or optimization",
    "easy_category": {
      "functionally_correct": 9,
      "partially_correct": 4,
      "incorrect_logic": 6,
      "complete_hallucination": 6,
      "estimated_avg_accuracy": "48%"
    },
    "medium_category": {
      "functionally_correct": 3,
      "partially_correct": 2,
      "incorrect_logic": 8,
      "complete_hallucination": 12,
      "estimated_avg_accuracy": "28%"
    },
    "overall_avg_accuracy": "38%"
  },
  "latency_analysis": {
    "performance_on_1gb_ram": {
      "average_inference": "16.32s per prompt",
      "variability": "High (2.6s to 26.2s)",
      "observation": "Longer prompts trigger repetitive hallucinations, significantly increasing latency"
    }
  },
  "error_patterns": {
    "repetitive_loops": {
      "count": 16,
      "percentage": "32%",
      "description": "Model gets stuck repeating same pattern infinitely",
      "impact_on_latency": "Increases execution time to max_tokens limit (~20-22s)",
      "examples": ["#12 (swap)", "#16 (check empty)", "#18 (uppercase)", "#22 (concatenate)", "#24 (even numbers)"]
    },
    "hallucinated_logic": {
      "count": 14,
      "percentage": "28%",
      "description": "Generates plausible-looking but functionally wrong code",
      "examples": ["#2 (reverse logic wrong)", "#3 (hardcoded primes)", "#13 (even/odd reversed)", "#10 (uses len() when asked not to)"]
    },
    "incomplete_generation": {
      "count": 9,
      "percentage": "18%",
      "description": "Code cuts off mid-function or mid-line",
      "examples": ["#19 (power)", "#25 (absolute)", "#27 (second largest)", "#35 (rotate list)"]
    },
    "url_hallucinations": {
      "count": 5,
      "percentage": "10%",
      "description": "Fabricates fake HackerRank/GeeksForGeeks URLs",
      "examples": ["#27", "#29", "#31", "#33", "#41"]
    }
  },
  "quality_highlights": {
    "good_solutions": [
      "#1: Factorial (correct recursive implementation)",
      "#4: Find max (correct iterative approach)",
      "#5: Sum list (correct built-in usage)",
      "#7: Palindrome (correct recursive logic)",
      "#8: Count vowels (functional implementation)",
      "#11: Average (correct calculation)",
      "#14: Find min (correct implementation)",
      "#26: Bubble sort (mostly correct logic)",
      "#33: Binary search (complete working solution)",
      "#42: Fibonacci (correct recursive)",
      "#44: Remove non-alphanumeric (correct)",
      "#50: GCD Euclidean (correct algorithm)"
    ],
    "total_correct": 12,
    "correct_percentage": "24%"
  },
  "resource_constraint_impact": {
    "ram_usage": "1GB constraint causes model to operate at minimal capacity",
    "inference_variability": "High variance (7.24s std dev) indicates unstable performance",
    "quality_degradation": "38% accuracy significantly below typical code generation benchmarks (60-70%)",
    "recommendation": "Model suitable for latency benchmarking only; unsuitable for production code generation at 1GB RAM"
  },
  "conclusion": "The tiny_starcoder_py model demonstrates severe quality limitations when constrained to 1GB RAM and 2 CPU cores, with only 24% of outputs producing functionally correct code. However, it successfully completes all 50 inferences with consistent latency metrics, making it suitable for system orchestration and communication latency benchmarking rather than code quality evaluation."
}